# Artisan Hub - Implementation Guide (Part 2)

## Continuation from Part 1

This document continues the implementation guide with:
- Growth Marketer Agent
- Event Scout Agent  
- Frontend Integration
- Complete Testing Procedures
- Deployment Guidelines

---

## Step 2.5: Growth Marketer Agent (DAY 8-9)

```python
# backend/agents/growth_marketer.py
from typing import Dict, List, Optional
from .base_agent import BaseAgent
from loguru import logger
import json

class GrowthMarketerAgent(BaseAgent):
    """
    Growth Marketer Agent
    
    Responsibilities:
    1. Identify adjacent market opportunities
    2. Analyze product innovation possibilities
    3. Provide pricing optimization suggestions
    4. Calculate ROI projections
    5. Discover trending products in artisan's niche
    6. Suggest modern adaptations of traditional crafts
    7. Identify high-margin applications
    
    Uses: Gemma 3 4B for complex market analysis
    """
    
    def __init__(self, ollama_client, vector_store, scraper_service):
        super().__init__(
            name="Growth Marketer",
            description="Identifies growth opportunities and market trends",
            ollama_client=ollama_client,
            vector_store=vector_store
        )
        self.scraper = scraper_service
    
    async def analyze(self, user_profile: Dict) -> Dict:
        """
        Analyze growth opportunities for the artisan
        
        Input format:
        {
            "craft_type": "pottery",
            "specialization": "blue pottery",
            "current_products": ["plates", "vases"],
            "location": {"city": "Jaipur", "state": "Rajasthan"},
            "typical_price_range": "Rs 500-2000" (optional)
        }
        
        Output format:
        {
            "trends": [
                {
                    "trend_name": "Ceramic jewelry",
                    "growth_rate": "300%",
                    "platform": "Etsy",
                    "evidence": "Found 50k+ searches/month",
                    "relevance_score": 0.9
                }
            ],
            "product_innovations": [
                {
                    "idea": "Blue pottery earrings",
                    "market_size": "Large",
                    "competition": "Medium",
                    "estimated_price_point": "Rs 800-1200",
                    "materials_needed": ["..."],
                    "skill_overlap": "95%"
                }
            ],
            "pricing_insights": {
                "current_market_avg": "Rs 1200",
                "premium_opportunity": "Rs 2500+",
                "volume_pricing": "Rs 600-800",
                "recommendation": "Position as premium traditional craft"
            },
            "roi_projections": [
                {
                    "scenario": "Add jewelry line",
                    "investment_needed": "Rs 15000",
                    "monthly_revenue_potential": "Rs 25000",
                    "breakeven_months": 3,
                    "confidence": 0.75
                }
            ],
            "marketing_channels": [
                {
                    "channel": "Instagram",
                    "audience_size": "5M+ India pottery enthusiasts",
                    "cost": "Free/Low",
                    "effort": "Medium"
                }
            ]
        }
        """
        self.log_execution("start", {"craft": user_profile.get("craft_type")})
        
        craft_type = user_profile.get("craft_type", "")
        specialization = user_profile.get("specialization", "")
        current_products = user_profile.get("current_products", [])
        
        # Step 1: Research trending products in this craft niche
        trends = await self._research_trends(craft_type, specialization)
        
        # Step 2: Generate product innovation ideas
        innovations = await self._generate_innovations(
            craft_type,
            specialization,
            current_products,
            trends
        )
        
        # Step 3: Analyze pricing strategies
        pricing = await self._analyze_pricing(craft_type, specialization)
        
        # Step 4: Calculate ROI projections
        roi_projections = await self._calculate_roi(innovations[:3])  # Top 3 ideas
        
        # Step 5: Identify marketing channels
        channels = await self._identify_channels(craft_type, user_profile.get("location"))
        
        self.log_execution("complete", {
            "trends_found": len(trends),
            "innovations": len(innovations)
        })
        
        return {
            "trends": trends,
            "product_innovations": innovations,
            "pricing_insights": pricing,
            "roi_projections": roi_projections,
            "marketing_channels": channels,
            "execution_logs": self.get_logs()
        }
    
    async def _research_trends(self, craft_type: str, specialization: str) -> List[Dict]:
        """
        Research current trends in the craft market
        """
        self.log_execution("researching_trends", {"craft": craft_type})
        
        # Search queries to find trends
        queries = [
            f"{craft_type} trends 2025",
            f"{specialization} trending products",
            f"{craft_type} best selling items Etsy",
            f"{craft_type} viral products Instagram",
            f"modern {craft_type} designs"
        ]
        
        all_trends = []
        
        for query in queries:
            results = await self.scraper.search(query, region="in", num_results=5)
            
            # Analyze each result for trend information
            for result in results[:3]:  # Top 3 per query
                # Scrape the page
                content = await self.scraper.scrape_page(result['url'])
                
                # Use LLM to extract trend info
                trend_prompt = f"""Analyze this content about {craft_type} trends:

URL: {result['url']}
Title: {result['title']}
Content snippet: {content[:1000]}

Extract trend information in JSON format:
{{
    "trend_name": "name of the trend",
    "description": "what the trend is about",
    "growth_indicators": "evidence of growth (numbers, percentages)",
    "platforms": ["where this trend is popular"],
    "relevance": "high/medium/low - how relevant to {specialization}"
}}

If no clear trend found, return {{"trend_name": null}}
Return ONLY valid JSON."""

                result_text = await self.ollama.reasoning_task(trend_prompt)
                
                try:
                    if "```json" in result_text:
                        result_text = result_text.split("```json")[1].split("```")[0]
                    trend_data = json.loads(result_text.strip())
                    
                    if trend_data.get("trend_name"):
                        # Calculate relevance score
                        relevance_map = {"high": 0.9, "medium": 0.6, "low": 0.3}
                        relevance_score = relevance_map.get(
                            trend_data.get("relevance", "medium"),
                            0.5
                        )
                        
                        all_trends.append({
                            "trend_name": trend_data["trend_name"],
                            "description": trend_data["description"],
                            "growth_rate": trend_data.get("growth_indicators", "Unknown"),
                            "platforms": trend_data.get("platforms", []),
                            "relevance_score": relevance_score,
                            "source": result['url']
                        })
                except:
                    continue
        
        # Sort by relevance and deduplicate
        all_trends.sort(key=lambda x: x["relevance_score"], reverse=True)
        unique_trends = self._deduplicate_trends(all_trends)
        
        return unique_trends[:5]  # Top 5 trends
    
    async def _generate_innovations(
        self,
        craft_type: str,
        specialization: str,
        current_products: List[str],
        trends: List[Dict]
    ) -> List[Dict]:
        """
        Generate product innovation ideas based on trends and skills
        """
        self.log_execution("generating_innovations", {"craft": craft_type})
        
        # Build context about trends
        trends_context = "\n".join([
            f"- {t['trend_name']}: {t['description']}"
            for t in trends[:3]
        ])
        
        innovation_prompt = f"""You are a product innovation consultant for artisans.

Artisan Profile:
- Craft: {craft_type} ({specialization})
- Current products: {', '.join(current_products)}

Current Market Trends:
{trends_context}

Generate 5 innovative product ideas that:
1. Build on the artisan's existing skills
2. Align with market trends
3. Can be produced with minimal additional investment
4. Have high profit potential
5. Are unique or differentiated

For each idea, provide in JSON format:
[
    {{
        "idea": "product name",
        "description": "what it is and why it's innovative",
        "market_size": "Small/Medium/Large",
        "competition": "Low/Medium/High",
        "estimated_price_point": "price range in Rs",
        "materials_needed": ["list of materials"],
        "skill_overlap_percent": 0-100,
        "unique_selling_point": "what makes it special",
        "target_customer": "who would buy this"
    }}
]

Return ONLY valid JSON array."""

        result = await self.ollama.reasoning_task(innovation_prompt)
        
        try:
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0]
            innovations = json.loads(result.strip())
            
            # Add confidence scores
            for innovation in innovations:
                # Calculate confidence based on skill overlap and market size
                skill_overlap = innovation.get("skill_overlap_percent", 50) / 100
                market_size_map = {"Large": 0.3, "Medium": 0.2, "Small": 0.1}
                market_score = market_size_map.get(innovation.get("market_size", "Medium"), 0.2)
                competition_map = {"Low": 0.3, "Medium": 0.2, "High": 0.1}
                competition_score = competition_map.get(innovation.get("competition", "Medium"), 0.2)
                
                confidence = skill_overlap * 0.5 + market_score + competition_score
                innovation["confidence"] = min(1.0, confidence)
            
            # Sort by confidence
            innovations.sort(key=lambda x: x["confidence"], reverse=True)
            
            return innovations
        except:
            logger.error("Failed to parse innovation ideas")
            return []
    
    async def _analyze_pricing(self, craft_type: str, specialization: str) -> Dict:
        """
        Analyze pricing strategies for the craft
        """
        self.log_execution("analyzing_pricing", {"craft": craft_type})
        
        # Search for pricing information
        queries = [
            f"{specialization} {craft_type} price India",
            f"{craft_type} pricing strategy handmade",
            f"how much does {specialization} sell for"
        ]
        
        pricing_data = []
        
        for query in queries:
            results = await self.scraper.search(query, region="in", num_results=3)
            
            for result in results[:2]:
                content = await self.scraper.scrape_page(result['url'])
                pricing_data.append(content[:500])
        
        # Analyze with LLM
        pricing_context = "\n---\n".join(pricing_data)
        
        pricing_prompt = f"""Analyze pricing information for {craft_type} ({specialization}):

Market Data:
{pricing_context}

Provide pricing insights in JSON format:
{{
    "current_market_avg": "average price range",
    "premium_opportunity": "price range for premium positioning",
    "volume_pricing": "price range for volume sales",
    "factors_affecting_price": ["list of factors"],
    "recommendation": "strategic pricing recommendation"
}}

Return ONLY valid JSON."""

        result = await self.ollama.reasoning_task(pricing_prompt)
        
        try:
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0]
            pricing_insights = json.loads(result.strip())
            return pricing_insights
        except:
            return {
                "current_market_avg": "Data unavailable",
                "recommendation": "Research local market prices"
            }
    
    async def _calculate_roi(self, innovations: List[Dict]) -> List[Dict]:
        """
        Calculate ROI projections for top innovation ideas
        """
        self.log_execution("calculating_roi", {"innovations_count": len(innovations)})
        
        roi_projections = []
        
        for innovation in innovations:
            # Use LLM to estimate costs and returns
            roi_prompt = f"""Calculate ROI projection for this product idea:

Product: {innovation['idea']}
Description: {innovation['description']}
Estimated Price: {innovation['estimated_price_point']}
Materials Needed: {', '.join(innovation['materials_needed'])}

Provide realistic estimates in JSON:
{{
    "initial_investment": {{
        "materials": 0,
        "tools": 0,
        "marketing": 0,
        "total": 0
    }},
    "monthly_costs": {{
        "materials_per_unit": 0,
        "time_hours_per_unit": 0,
        "units_per_month_realistic": 0
    }},
    "revenue_projection": {{
        "price_per_unit": 0,
        "units_sold_month": 0,
        "monthly_revenue": 0
    }},
    "breakeven_analysis": {{
        "months_to_breakeven": 0,
        "units_to_breakeven": 0
    }}
}}

All amounts in Indian Rupees. Return ONLY valid JSON."""

            result = await self.ollama.reasoning_task(roi_prompt)
            
            try:
                if "```json" in result:
                    result = result.split("```json")[1].split("```")[0]
                roi_data = json.loads(result.strip())
                
                roi_projections.append({
                    "scenario": innovation['idea'],
                    "investment_needed": roi_data['initial_investment']['total'],
                    "monthly_revenue_potential": roi_data['revenue_projection']['monthly_revenue'],
                    "breakeven_months": roi_data['breakeven_analysis']['months_to_breakeven'],
                    "confidence": innovation.get('confidence', 0.5)
                })
            except:
                continue
        
        return roi_projections
    
    async def _identify_channels(self, craft_type: str, location: Dict) -> List[Dict]:
        """
        Identify marketing channels suitable for the artisan
        """
        self.log_execution("identifying_channels", {"craft": craft_type})
        
        channels_prompt = f"""Identify the best marketing channels for an artisan making {craft_type} in India.

Consider:
- Online platforms (Instagram, Facebook, Etsy, Amazon Handmade)
- Local opportunities (craft fairs, exhibitions, local stores)
- B2B channels (hotels, restaurants, interior designers)
- Export opportunities

Provide in JSON format:
[
    {{
        "channel": "channel name",
        "audience_size": "estimated reach",
        "cost": "Free/Low/Medium/High",
        "effort": "Low/Medium/High",
        "best_for": "what products/goals",
        "getting_started": "first steps to start"
    }}
]

Return ONLY valid JSON array with top 5 channels."""

        result = await self.ollama.reasoning_task(channels_prompt)
        
        try:
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0]
            channels = json.loads(result.strip())
            return channels
        except:
            return []
    
    def _deduplicate_trends(self, trends: List[Dict]) -> List[Dict]:
        """Remove duplicate trends by name"""
        seen = set()
        unique = []
        
        for trend in trends:
            name = trend['trend_name'].lower()
            if name not in seen:
                seen.add(name)
                unique.append(trend)
        
        return unique


# Test the Growth Marketer Agent
async def test_growth_marketer():
    from core.ollama_client import OllamaClient
    from core.vector_store import ArtisanVectorStore
    from scraping.web_scraper import WebScraperService
    
    ollama = OllamaClient()
    vector_store = ArtisanVectorStore("./data/test_chroma")
    scraper = WebScraperService()
    
    agent = GrowthMarketerAgent(ollama, vector_store, scraper)
    
    # Test input
    test_input = {
        "craft_type": "pottery",
        "specialization": "blue pottery",
        "current_products": ["decorative plates", "vases", "bowls"],
        "location": {"city": "Jaipur", "state": "Rajasthan"},
        "user_id": "test_user_001"
    }
    
    print("Analyzing growth opportunities...")
    result = await agent.analyze(test_input)
    
    print("\n=== MARKET TRENDS ===")
    for i, trend in enumerate(result['trends'][:3]):
        print(f"\n{i+1}. {trend['trend_name']}")
        print(f"   Growth: {trend['growth_rate']}")
        print(f"   Relevance: {trend['relevance_score']:.2f}")
    
    print("\n=== PRODUCT INNOVATIONS ===")
    for i, innovation in enumerate(result['product_innovations'][:3]):
        print(f"\n{i+1}. {innovation['idea']}")
        print(f"   Price: {innovation['estimated_price_point']}")
        print(f"   Confidence: {innovation['confidence']:.2f}")
    
    print("\n=== ROI PROJECTIONS ===")
    for projection in result['roi_projections']:
        print(f"\n{projection['scenario']}")
        print(f"   Investment: Rs {projection['investment_needed']}")
        print(f"   Monthly Revenue: Rs {projection['monthly_revenue_potential']}")
        print(f"   Breakeven: {projection['breakeven_months']} months")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_growth_marketer())
```

---

## Step 2.6: Event Scout Agent (DAY 10-11)

```python
# backend/agents/event_scout.py
from typing import Dict, List, Optional
from .base_agent import BaseAgent
from loguru import logger
import json
from datetime import datetime, timedelta

class EventScoutAgent(BaseAgent):
    """
    Event Scout Agent
    
    Responsibilities:
    1. Find craft fairs and exhibitions
    2. Discover relevant marketplaces
    3. Identify workshop opportunities
    4. Scout government schemes for artisans
    5. Match events to artisan's location and craft
    6. Calculate event ROI (booth cost vs potential revenue)
    7. Provide contact details for event organizers
    
    Uses: Gemma 3 4B for matching and analysis, 1B for classification
    """
    
    def __init__(self, ollama_client, vector_store, scraper_service, maps_service):
        super().__init__(
            name="Event Scout",
            description="Finds relevant events and opportunities",
            ollama_client=ollama_client,
            vector_store=vector_store
        )
        self.scraper = scraper_service
        self.maps = maps_service
    
    async def analyze(self, user_profile: Dict) -> Dict:
        """
        Find events and opportunities for the artisan
        
        Input format:
        {
            "craft_type": "pottery",
            "location": {"city": "Jaipur", "state": "Rajasthan", "lat": 26.9, "lon": 75.8},
            "available_months": ["November", "December", "January"],
            "travel_radius_km": 100
        }
        
        Output format:
        {
            "upcoming_events": [
                {
                    "name": "Jaipur Craft Fair 2025",
                    "type": "craft_fair",
                    "date": "2025-11-15",
                    "location": {"city": "Jaipur", "venue": "..."},
                    "distance_km": 5,
                    "booth_cost": "Rs 5000-10000",
                    "expected_footfall": "10000+",
                    "relevance_score": 0.95,
                    "revenue_potential": "Rs 50000-100000",
                    "contact": {"phone": "", "email": "", "website": ""},
                    "booking_deadline": "2025-10-15",
                    "requirements": ["GST certificate", "craft samples"]
                }
            ],
            "government_schemes": [
                {
                    "scheme_name": "PM Vishwakarma Yojana",
                    "benefits": ["...", "..."],
                    "eligibility": "Traditional artisans",
                    "how_to_apply": "...",
                    "contact": "..."
                }
            ],
            "workshop_opportunities": [...],
            "total_events_found": 12,
            "events_within_radius": 8
        }
        """
        self.log_execution("start", {"location": user_profile.get("location")})
        
        craft_type = user_profile.get("craft_type", "")
        location = user_profile.get("location", {})
        travel_radius = user_profile.get("travel_radius_km", 100)
        
        # Step 1: Search for upcoming craft fairs and exhibitions
        events = await self._search_events(craft_type, location, travel_radius)
        
        # Step 2: Find government schemes
        schemes = await self._find_government_schemes(craft_type, location)
        
        # Step 3: Discover workshop opportunities
        workshops = await self._find_workshops(craft_type, location)
        
        # Step 4: Calculate ROI for each event
        for event in events:
            event["roi_analysis"] = await self._calculate_event_roi(event, craft_type)
        
        # Step 5: Sort by relevance and proximity
        events.sort(
            key=lambda x: (x["relevance_score"] * 0.7 + (1 - x["distance_km"]/travel_radius) * 0.3),
            reverse=True
        )
        
        within_radius = sum(1 for e in events if e["distance_km"] <= travel_radius)
        
        self.log_execution("complete", {
            "events_found": len(events),
            "within_radius": within_radius
        })
        
        return {
            "upcoming_events": events,
            "government_schemes": schemes,
            "workshop_opportunities": workshops,
            "total_events_found": len(events),
            "events_within_radius": within_radius,
            "execution_logs": self.get_logs()
        }
    
    async def _search_events(
        self,
        craft_type: str,
        location: Dict,
        radius_km: int
    ) -> List[Dict]:
        """Search for craft events"""
        self.log_execution("searching_events", {"craft": craft_type, "location": location})
        
        city = location.get("city", "")
        state = location.get("state", "")
        
        # Build search queries
        current_year = datetime.now().year
        next_year = current_year + 1
        
        queries = [
            f"craft fair {city} {state} {current_year}",
            f"{craft_type} exhibition India {current_year}",
            f"artisan market {state} upcoming",
            f"handicraft mela {city} {current_year}",
            f"dilli haat {state} schedule",
            f"{craft_type} festival India {next_year}"
        ]
        
        all_events = []
        
        for query in queries:
            results = await self.scraper.search(query, region="in", num_results=5)
            
            for result in results:
                # Scrape event details
                content = await self.scraper.scrape_page(result['url'])
                
                # Extract event information with LLM
                event_prompt = f"""Extract event information from this webpage:

URL: {result['url']}
Title: {result['title']}
Content: {content[:1500]}

Extract in JSON format:
{{
    "name": "event name",
    "type": "craft_fair/exhibition/market/festival/workshop",
    "date": "YYYY-MM-DD or date range",
    "location": {{
        "city": "",
        "venue": "",
        "address": ""
    }},
    "booth_cost": "cost information if mentioned",
    "expected_footfall": "attendance numbers if mentioned",
    "organizer": "organizer name",
    "contact": {{
        "phone": "",
        "email": "",
        "website": "{result['url']}"
    }},
    "booking_deadline": "deadline if mentioned",
    "description": "brief description"
}}

If this is not an event page, return {{"name": null}}
Return ONLY valid JSON."""

                event_result = await self.ollama.reasoning_task(event_prompt)
                
                try:
                    if "```json" in event_result:
                        event_result = event_result.split("```json")[1].split("```")[0]
                    event_data = json.loads(event_result.strip())
                    
                    if event_data.get("name"):
                        # Calculate distance
                        event_location = event_data.get("location", {})
                        distance = await self._calculate_distance(
                            location,
                            event_location
                        )
                        
                        event_data["distance_km"] = distance
                        
                        # Calculate relevance score
                        relevance = await self._calculate_event_relevance(
                            event_data,
                            craft_type
                        )
                        event_data["relevance_score"] = relevance
                        
                        all_events.append(event_data)
                except:
                    continue
        
        # Deduplicate by name
        unique_events = self._deduplicate_events(all_events)
        
        return unique_events
    
    async def _find_government_schemes(self, craft_type: str, location: Dict) -> List[Dict]:
        """Find government schemes for artisans"""
        self.log_execution("finding_schemes", {"craft": craft_type})
        
        queries = [
            "government scheme for artisans India 2025",
            f"{craft_type} artisan subsidy India",
            "PM Vishwakarma Yojana benefits",
            "handicraft artisan financial support India"
        ]
        
        schemes = []
        
        for query in queries:
            results = await self.scraper.search(query, region="in", num_results=3)
            
            for result in results[:2]:
                content = await self.scraper.scrape_page(result['url'])
                
                scheme_prompt = f"""Extract government scheme information:

Content: {content[:1000]}

Extract in JSON format:
{{
    "scheme_name": "name of scheme",
    "benefits": ["list of benefits"],
    "eligibility": "who can apply",
    "how_to_apply": "application process",
    "contact": "contact information",
    "deadline": "application deadline if any"
}}

If no scheme found, return {{"scheme_name": null}}
Return ONLY valid JSON."""

                result_text = await self.ollama.reasoning_task(scheme_prompt)
                
                try:
                    if "```json" in result_text:
                        result_text = result_text.split("```json")[1].split("```")[0]
                    scheme_data = json.loads(result_text.strip())
                    
                    if scheme_data.get("scheme_name"):
                        scheme_data["source"] = result['url']
                        schemes.append(scheme_data)
                except:
                    continue
        
        # Deduplicate
        unique_schemes = self._deduplicate_schemes(schemes)
        return unique_schemes[:5]
    
    async def _find_workshops(self, craft_type: str, location: Dict) -> List[Dict]:
        """Find workshop and teaching opportunities"""
        # Similar implementation to events search
        # Focus on teaching/workshop opportunities
        return []
    
    async def _calculate_distance(
        self,
        location1: Dict,
        location2: Dict
    ) -> float:
        """Calculate distance between two locations"""
        # Use maps service to calculate distance
        # If coordinates not available, estimate based on cities
        
        city1 = location1.get("city", "").lower()
        city2 = location2.get("city", "").lower()
        
        if city1 == city2:
            return 5  # Same city, assume 5km
        
        # Use geopy or mapbox to get actual distance
        # For now, return estimate
        return 50  # Default estimate
    
    async def _calculate_event_relevance(self, event: Dict, craft_type: str) -> float:
        """Calculate how relevant the event is to the artisan"""
        relevance = 0.5  # Base score
        
        # Check event type
        event_type = event.get("type", "").lower()
        if craft_type.lower() in event.get("name", "").lower():
            relevance += 0.3
        
        if event_type in ["craft_fair", "artisan_market"]:
            relevance += 0.2
        
        return min(1.0, relevance)
    
    async def _calculate_event_roi(self, event: Dict, craft_type: str) -> Dict:
        """Calculate expected ROI for attending event"""
        roi_prompt = f"""Calculate ROI for attending this event:

Event: {event.get('name')}
Type: {event.get('type')}
Booth Cost: {event.get('booth_cost', 'Unknown')}
Expected Footfall: {event.get('expected_footfall', 'Unknown')}
Craft Type: {craft_type}

Estimate in JSON:
{{
    "total_cost": {{
        "booth_rental": 0,
        "travel": 0,
        "accommodation": 0,
        "inventory": 0,
        "total": 0
    }},
    "revenue_estimate": {{
        "conservative": 0,
        "realistic": 0,
        "optimistic": 0
    }},
    "break_even_units": 0,
    "recommendation": "Attend/Maybe/Skip with reasoning"
}}

Amounts in Rs. Return ONLY valid JSON."""

        result = await self.ollama.reasoning_task(roi_prompt)
        
        try:
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0]
            roi_data = json.loads(result.strip())
            return roi_data
        except:
            return {"error": "Could not calculate ROI"}
    
    def _deduplicate_events(self, events: List[Dict]) -> List[Dict]:
        """Remove duplicate events by name and date"""
        seen = set()
        unique = []
        
        for event in events:
            key = f"{event.get('name', '')}_{event.get('date', '')}"
            if key not in seen:
                seen.add(key)
                unique.append(event)
        
        return unique
    
    def _deduplicate_schemes(self, schemes: List[Dict]) -> List[Dict]:
        """Remove duplicate schemes by name"""
        seen = set()
        unique = []
        
        for scheme in schemes:
            name = scheme.get('scheme_name', '').lower()
            if name not in seen:
                seen.add(name)
                unique.append(scheme)
        
        return unique


# Test the Event Scout Agent
async def test_event_scout():
    from core.ollama_client import OllamaClient
    from core.vector_store import ArtisanVectorStore
    from scraping.web_scraper import WebScraperService
    from services.maps_service import MapsService
    
    ollama = OllamaClient()
    vector_store = ArtisanVectorStore("./data/test_chroma")
    scraper = WebScraperService()
    maps = MapsService()
    
    agent = EventScoutAgent(ollama, vector_store, scraper, maps)
    
    # Test input
    test_input = {
        "craft_type": "pottery",
        "location": {
            "city": "Jaipur",
            "state": "Rajasthan",
            "country": "India"
        },
        "travel_radius_km": 100,
        "user_id": "test_user_001"
    }
    
    print("Scouting for events...")
    result = await agent.analyze(test_input)
    
    print(f"\n=== EVENTS FOUND: {result['total_events_found']} ===")
    print(f"Within radius: {result['events_within_radius']}")
    
    for i, event in enumerate(result['upcoming_events'][:3]):
        print(f"\n{i+1}. {event['name']}")
        print(f"   Date: {event.get('date', 'TBD')}")
        print(f"   Location: {event['location'].get('city')}")
        print(f"   Distance: {event['distance_km']} km")
        print(f"   Relevance: {event['relevance_score']:.2f}")
    
    if result['government_schemes']:
        print(f"\n=== GOVERNMENT SCHEMES: {len(result['government_schemes'])} ===")
        for scheme in result['government_schemes']:
            print(f"\n- {scheme['scheme_name']}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_event_scout())
```

---

## Phase 3: Frontend Integration (Week 4)

### Simple HTML/JS Frontend (Day 12-13)

```html
<!-- frontend/index.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Artisan Hub - AI Assistant for Craftspeople</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            width: 100%;
            max-width: 900px;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, #E07A5F 0%, #C4624A 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .header p {
            opacity: 0.9;
        }
        
        .chat-container {
            height: 500px;
            overflow-y: auto;
            padding: 20px;
            background: #f8f9fa;
        }
        
        .message {
            margin-bottom: 15px;
            display: flex;
            align-items: flex-start;
        }
        
        .message.user {
            justify-content: flex-end;
        }
        
        .message-content {
            max-width: 70%;
            padding: 15px;
            border-radius: 15px;
            line-height: 1.5;
        }
        
        .message.user .message-content {
            background: #667eea;
            color: white;
        }
        
        .message.assistant .message-content {
            background: white;
            border: 1px solid #e0e0e0;
        }
        
        .message-avatar {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin: 0 10px;
        }
        
        .message.user .message-avatar {
            background: #764ba2;
            color: white;
        }
        
        .message.assistant .message-avatar {
            background: #E07A5F;
            color: white;
        }
        
        .input-container {
            display: flex;
            padding: 20px;
            border-top: 1px solid #e0e0e0;
            background: white;
        }
        
        .input-container input {
            flex: 1;
            padding: 15px;
            border: 2px solid #e0e0e0;
            border-radius: 25px;
            font-size: 16px;
            outline: none;
            transition: border-color 0.3s;
        }
        
        .input-container input:focus {
            border-color: #667eea;
        }
        
        .input-container button {
            margin-left: 10px;
            padding: 15px 30px;
            background: linear-gradient(135deg, #E07A5F 0%, #C4624A 100%);
            color: white;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-size: 16px;
            font-weight: bold;
            transition: transform 0.2s;
        }
        
        .input-container button:hover {
            transform: scale(1.05);
        }
        
        .input-container button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .loading {
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #667eea;
            animation: pulse 1.5s ease-in-out infinite;
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 0.3; }
            50% { opacity: 1; }
        }
        
        .agent-panel {
            margin: 15px 0;
            padding: 15px;
            background: #f0f4ff;
            border-left: 4px solid #667eea;
            border-radius: 5px;
        }
        
        .agent-panel h4 {
            color: #667eea;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üè∫ Artisan Hub</h1>
            <p>AI-Powered Assistant for Craftspeople</p>
        </div>
        
        <div class="chat-container" id="chatContainer">
            <div class="message assistant">
                <div class="message-avatar">AI</div>
                <div class="message-content">
                    Welcome to Artisan Hub! I'm here to help you discover suppliers, find growth opportunities, and connect with relevant events. Tell me about yourself and your craft!
                </div>
            </div>
        </div>
        
        <div class="input-container">
            <input 
                type="text" 
                id="userInput" 
                placeholder="Tell me about your craft..." 
                onkeypress="if(event.key === 'Enter') sendMessage()"
            />
            <button onclick="sendMessage()" id="sendButton">Send</button>
        </div>
    </div>
    
    <script>
        const API_BASE = "http://localhost:8000";
        let conversationHistory = [];
        
        async function sendMessage() {
            const input = document.getElementById('userInput');
            const message = input.value.trim();
            
            if (!message) return;
            
            // Add user message to chat
            addMessage('user', message);
            input.value = '';
            
            // Disable input while processing
            const sendButton = document.getElementById('sendButton');
            sendButton.disabled = true;
            sendButton.textContent = 'Thinking...';
            
            // Add to history
            conversationHistory.push({
                role: 'user',
                content: message
            });
            
            try {
                // Send to API
                const response = await fetch(`${API_BASE}/chat/send`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        message: message,
                        conversation_history: conversationHistory
                    })
                });
                
                if (!response.ok) {
                    throw new Error('API request failed');
                }
                
                const data = await response.json();
                
                // Add assistant response
                addMessage('assistant', data.response);
                
                // Add to history
                conversationHistory.push({
                    role: 'assistant',
                    content: data.response
                });
                
                // If this is first message, trigger agent analysis
                if (conversationHistory.length === 2) {
                    setTimeout(() => analyzeProfile(message), 1000);
                }
                
            } catch (error) {
                console.error('Error:', error);
                addMessage('assistant', 'Sorry, I encountered an error. Please try again.');
            } finally {
                sendButton.disabled = false;
                sendButton.textContent = 'Send';
            }
        }
        
        function addMessage(role, content) {
            const container = document.getElementById('chatContainer');
            
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            const avatarDiv = document.createElement('div');
            avatarDiv.className = 'message-avatar';
            avatarDiv.textContent = role === 'user' ? 'You' : 'AI';
            
            const contentDiv = document.createElement('div');
            contentDiv.className = 'message-content';
            contentDiv.innerHTML = formatMessage(content);
            
            if (role === 'user') {
                messageDiv.appendChild(contentDiv);
                messageDiv.appendChild(avatarDiv);
            } else {
                messageDiv.appendChild(avatarDiv);
                messageDiv.appendChild(contentDiv);
            }
            
            container.appendChild(messageDiv);
            container.scrollTop = container.scrollHeight;
        }
        
        function formatMessage(content) {
            // Simple formatting: convert URLs to links, add line breaks
            return content
                .replace(/\n/g, '<br>')
                .replace(/(https?:\/\/[^\s]+)/g, '<a href="$1" target="_blank">$1</a>');
        }
        
        async function analyzeProfile(profileText) {
            addMessage('assistant', 'üîç Analyzing your profile with our AI agents...');
            
            try {
                // Call Profile Analyst
                const profileResponse = await fetch(`${API_BASE}/agents/profile-analyst`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ input_text: profileText })
                });
                
                if (!profileResponse.ok) throw new Error('Profile analysis failed');
                
                const profileData = await profileResponse.json();
                
                // Show profile results
                showAgentResults('Profile Analyst', profileData);
                
                // Call Supply Hunter
                addMessage('assistant', 'üîç Searching for suppliers...');
                
                const supplyResponse = await fetch(`${API_BASE}/agents/supply-hunter`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        craft_type: profileData.craft_type,
                        supplies_needed: profileData.inferred_needs.supplies,
                        location: profileData.location
                    })
                });
                
                if (supplyResponse.ok) {
                    const supplyData = await supplyResponse.json();
                    showSupplierResults(supplyData);
                }
                
                // Call Growth Marketer
                addMessage('assistant', 'üí° Identifying growth opportunities...');
                
                const growthResponse = await fetch(`${API_BASE}/agents/growth-marketer`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        craft_type: profileData.craft_type,
                        specialization: profileData.specialization,
                        current_products: profileData.typical_products,
                        location: profileData.location
                    })
                });
                
                if (growthResponse.ok) {
                    const growthData = await growthResponse.json();
                    showGrowthResults(growthData);
                }
                
            } catch (error) {
                console.error('Analysis error:', error);
                addMessage('assistant', 'I encountered an issue analyzing your profile. Let\'s try a different approach.');
            }
        }
        
        function showAgentResults(agentName, data) {
            const container = document.getElementById('chatContainer');
            
            const panel = document.createElement('div');
            panel.className = 'agent-panel';
            
            panel.innerHTML = `
                <h4>‚úì ${agentName} Results</h4>
                <p><strong>Craft:</strong> ${data.craft_type} - ${data.specialization}</p>
                <p><strong>Location:</strong> ${data.location.city}, ${data.location.state}</p>
                <p><strong>Inferred Needs:</strong></p>
                <ul>
                    <li><strong>Tools:</strong> ${data.inferred_needs.tools.join(', ')}</li>
                    <li><strong>Supplies:</strong> ${data.inferred_needs.supplies.join(', ')}</li>
                </ul>
            `;
            
            container.appendChild(panel);
            container.scrollTop = container.scrollHeight;
        }
        
        function showSupplierResults(data) {
            const container = document.getElementById('chatContainer');
            
            const panel = document.createElement('div');
            panel.className = 'agent-panel';
            
            let html = `<h4>‚úì Supply Hunter: Found ${data.total_suppliers_found} suppliers</h4>`;
            
            data.suppliers.slice(0, 3).forEach((supplier, i) => {
                html += `
                    <p><strong>${i + 1}. ${supplier.name}</strong></p>
                    <p>Location: ${supplier.location.city} | Confidence: ${(supplier.verification.confidence * 100).toFixed(0)}%</p>
                `;
            });
            
            panel.innerHTML = html;
            container.appendChild(panel);
            container.scrollTop = container.scrollHeight;
        }
        
        function showGrowthResults(data) {
            const container = document.getElementById('chatContainer');
            
            const panel = document.createElement('div');
            panel.className = 'agent-panel';
            
            let html = `<h4>‚úì Growth Marketer: Opportunities Found</h4>`;
            
            if (data.trends && data.trends.length > 0) {
                html += `<p><strong>Top Trend:</strong> ${data.trends[0].trend_name} (${data.trends[0].growth_rate})</p>`;
            }
            
            if (data.product_innovations && data.product_innovations.length > 0) {
                html += `<p><strong>Innovation Idea:</strong> ${data.product_innovations[0].idea}</p>`;
                html += `<p>${data.product_innovations[0].description}</p>`;
            }
            
            panel.innerHTML = html;
            container.appendChild(panel);
            container.scrollTop = container.scrollHeight;
        }
    </script>
</body>
</html>
```

---

## Complete Testing & Verification (Week 5-6)

### Comprehensive Test Suite

```python
# backend/tests/test_complete_system.py
import pytest
import asyncio
from core.ollama_client import OllamaClient
from core.vector_store import ArtisanVectorStore
from agents.profile_analyst import ProfileAnalystAgent
from agents.supply_hunter import SupplyHunterAgent
from agents.growth_marketer import GrowthMarketerAgent
from agents.event_scout import EventScoutAgent
from scraping.web_scraper import WebScraperService

@pytest.mark.asyncio
class TestCompleteSystem:
    """End-to-end system tests"""
    
    @pytest.fixture
    async def setup_system(self):
        """Setup all components"""
        ollama = OllamaClient()
        vector_store = ArtisanVectorStore("./data/test_chroma")
        scraper = WebScraperService()
        
        yield {
            'ollama': ollama,
            'vector_store': vector_store,
            'scraper': scraper
        }
    
    async def test_potter_workflow(self, setup_system):
        """Test complete workflow for a potter"""
        components = setup_system
        
        # Step 1: Profile Analysis
        profile_agent = ProfileAnalystAgent(
            components['ollama'],
            components['vector_store']
        )
        
        input_text = """I'm Raj Kumar, I make traditional blue pottery in Jaipur.
        I've been doing this for 15 years, learned from my father.
        We specialize in decorative plates, vases, and tiles with intricate floral patterns."""
        
        profile_result = await profile_agent.analyze({
            'input_text': input_text,
            'user_id': 'test_potter_001'
        })
        
        # Verify profile extraction
        assert profile_result['craft_type'] == 'pottery'
        assert 'jaipur' in profile_result['location']['city'].lower()
        assert len(profile_result['inferred_needs']['tools']) > 0
        
        print("‚úì Profile Analysis: PASS")
        
        # Step 2: Supply Hunting
        supply_agent = SupplyHunterAgent(
            components['ollama'],
            components['vector_store'],
            components['scraper']
        )
        
        supply_result = await supply_agent.analyze({
            'craft_type': profile_result['craft_type'],
            'supplies_needed': profile_result['inferred_needs']['supplies'],
            'location': profile_result['location']
        })
        
        # Verify suppliers found
        assert supply_result['total_suppliers_found'] > 0
        assert supply_result['india_suppliers'] > 0
        
        print(f"‚úì Supply Hunter: Found {supply_result['total_suppliers_found']} suppliers")
        
        # Step 3: Growth Marketing
        growth_agent = GrowthMarketerAgent(
            components['ollama'],
            components['vector_store'],
            components['scraper']
        )
        
        growth_result = await growth_agent.analyze({
            'craft_type': profile_result['craft_type'],
            'specialization': profile_result['specialization'],
            'current_products': profile_result['typical_products'],
            'location': profile_result['location']
        })
        
        # Verify growth insights
        assert len(growth_result['product_innovations']) > 0
        assert 'pricing_insights' in growth_result
        
        print(f"‚úì Growth Marketer: {len(growth_result['product_innovations'])} innovations found")
        
        print("\n‚úì‚úì‚úì COMPLETE WORKFLOW TEST: PASSED ‚úì‚úì‚úì")

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

---

## Final Deployment Checklist

### Pre-Deployment Verification:

```bash
#!/bin/bash
# deployment_check.sh

echo "üîç Running Pre-Deployment Checks..."

# Check 1: Ollama
echo "\n1. Checking Ollama..."
if ollama list | grep -q "gemma3:4b"; then
    echo "   ‚úì gemma3:4b found"
else
    echo "   ‚úó gemma3:4b NOT FOUND"
    exit 1
fi

if ollama list | grep -q "gemma3:1b"; then
    echo "   ‚úì gemma3:1b found"
else
    echo "   ‚úó gemma3:1b NOT FOUND"
    exit 1
fi

if ollama list | grep -q "gemma3:embed"; then
    echo "   ‚úì gemma3:embed found"
else
    echo "   ‚úó gemma3:embed NOT FOUND"
    exit 1
fi

# Check 2: Python dependencies
echo "\n2. Checking Python dependencies..."
python -c "import fastapi" 2>/dev/null && echo "   ‚úì FastAPI" || { echo "   ‚úó FastAPI"; exit 1; }
python -c "import chromadb" 2>/dev/null && echo "   ‚úì ChromaDB" || { echo "   ‚úó ChromaDB"; exit 1; }
python -c "import playwright" 2>/dev/null && echo "   ‚úì Playwright" || { echo "   ‚úó Playwright"; exit 1; }

# Check 3: Environment variables
echo "\n3. Checking environment..."
if [ -z "$SERPAPI_KEY" ]; then
    echo "   ‚úó SERPAPI_KEY not set"
    exit 1
else
    echo "   ‚úì SERPAPI_KEY configured"
fi

# Check 4: Backend health
echo "\n4. Checking backend..."
if curl -s http://localhost:8000/health | grep -q "healthy"; then
    echo "   ‚úì Backend is healthy"
else
    echo "   ‚úó Backend not responding"
    exit 1
fi

echo "\n‚úì‚úì‚úì ALL CHECKS PASSED ‚úì‚úì‚úì"
```

---

This completes the implementation guide. You now have:
1. Complete agent implementations
2. Web scraping with verification
3. Frontend integration
4. Testing procedures
5. Deployment checklist

